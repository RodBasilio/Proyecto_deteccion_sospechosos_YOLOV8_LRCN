{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4f4d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define your input and output directories\n",
    "input_dir = 'golpes_3_340\\images'\n",
    "output_dir = 'dataug'\n",
    "label_dir = 'golpes_3_340\\labels'\n",
    "\n",
    "# Make sure the output directories exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_data(image, bbox, keypoints):\n",
    "    # Random rotation\n",
    "    angle = np.random.uniform(-10, 10)\n",
    "    rows, cols = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    image = cv2.warpAffine(image, M, (cols, rows))\n",
    "\n",
    "    # Random horizontal flip\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        bbox[0], bbox[2] = 1 - bbox[2], 1 - bbox[0]  # Adjust bounding box x-coordinates\n",
    "\n",
    "        # Flip keypoints\n",
    "        for i in range(0, len(keypoints), 2):\n",
    "            keypoints[i] = 1 - keypoints[i]\n",
    "\n",
    "    return image, bbox, keypoints\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Perform data augmentation\n",
    "        augmented_image, augmented_bbox, augmented_keypoints = augment_data(image, bbox, keypoints)\n",
    "\n",
    "        # Save augmented image\n",
    "        augmented_image_path = os.path.join(output_dir, 'aug_' + filename)\n",
    "        cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Save augmented labels\n",
    "        augmented_label_path = os.path.join(output_dir, 'aug_' + filename[:-4] + '.txt')\n",
    "        with open(augmented_label_path, 'w') as augmented_label_file:\n",
    "            augmented_label_file.write('0 {} {} {} {} '.format(*augmented_bbox))\n",
    "            augmented_label_file.write(' '.join(map(str, augmented_keypoints)))\n",
    "\n",
    "print(\"Data augmentation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8743f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def draw_bbox_and_keypoints(image, bbox, keypoints, color=(255, 0, 0)):\n",
    "    # Draw bounding box\n",
    "    x, y, w, h = bbox\n",
    "    pt1 = (int(x * image.shape[1]), int(y * image.shape[0]))\n",
    "    pt2 = (int((x + w) * image.shape[1]), int((y + h) * image.shape[0]))\n",
    "    cv2.rectangle(image, pt1, pt2, color, 2)\n",
    "\n",
    "    # Draw keypoints\n",
    "    for i in range(0, len(keypoints), 2):\n",
    "        kp_x = int(keypoints[i] * image.shape[1])\n",
    "        kp_y = int(keypoints[i + 1] * image.shape[0])\n",
    "        cv2.circle(image, (kp_x, kp_y), 3, color, -1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define your input directory\n",
    "input_dir = 'dataug'\n",
    "\n",
    "label_dir = 'dataug'\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Draw bounding box and keypoints on the image\n",
    "        image_with_annotations = draw_bbox_and_keypoints(image.copy(), bbox, keypoints)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Annotations Verification', cv2.cvtColor(image_with_annotations, cv2.COLOR_RGB2BGR))\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d79712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define your input and output directories\n",
    "input_dir = 'golpes_3_340\\images'\n",
    "output_dir = 'dataug'\n",
    "label_dir = 'golpes_3_340\\labels'\n",
    "\n",
    "\n",
    "# Make sure the output directories exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Helper functions for bounding box and keypoints transformations\n",
    "def flip_bbox(bbox, image_width):\n",
    "    return [image_width - bbox[2], bbox[1], image_width - bbox[0], bbox[3]]\n",
    "\n",
    "def rotate_bbox(bbox, angle, image_width, image_height):\n",
    "    center_x = (bbox[0] + bbox[2]) / 2\n",
    "    center_y = (bbox[1] + bbox[3]) / 2\n",
    "\n",
    "    new_center_x = center_x * np.cos(np.radians(angle)) - center_y * np.sin(np.radians(angle))\n",
    "    new_center_y = center_x * np.sin(np.radians(angle)) + center_y * np.cos(np.radians(angle))\n",
    "\n",
    "    width = bbox[2] - bbox[0]\n",
    "    height = bbox[3] - bbox[1]\n",
    "\n",
    "    new_width = np.abs(width * np.cos(np.radians(angle))) + np.abs(height * np.sin(np.radians(angle)))\n",
    "    new_height = np.abs(height * np.cos(np.radians(angle))) + np.abs(width * np.sin(np.radians(angle)))\n",
    "\n",
    "    x_min = max(0, new_center_x - new_width / 2)\n",
    "    y_min = max(0, new_center_y - new_height / 2)\n",
    "    x_max = min(image_width, new_center_x + new_width / 2)\n",
    "    y_max = min(image_height, new_center_y + new_height / 2)\n",
    "\n",
    "    return [x_min, y_min, x_max, y_max]\n",
    "\n",
    "def rotate_keypoints(keypoints, angle, image_width, image_height):\n",
    "    rotated_keypoints = []\n",
    "\n",
    "    for i in range(0, len(keypoints), 2):\n",
    "        x = keypoints[i]\n",
    "        y = keypoints[i + 1]\n",
    "\n",
    "        new_x = x * np.cos(np.radians(angle)) - y * np.sin(np.radians(angle))\n",
    "        new_y = x * np.sin(np.radians(angle)) + y * np.cos(np.radians(angle))\n",
    "\n",
    "        rotated_keypoints.extend([new_x, new_y])\n",
    "\n",
    "    return rotated_keypoints\n",
    "\n",
    "def flip_keypoints(keypoints, image_width):\n",
    "    flipped_keypoints = [image_width - kp if i % 2 == 0 else kp for i, kp in enumerate(keypoints)]\n",
    "    return flipped_keypoints\n",
    "\n",
    "def zoom_bbox(bbox, zoom_factor, image_width):\n",
    "    center_x = (bbox[0] + bbox[2]) / 2\n",
    "\n",
    "    new_width = (bbox[2] - bbox[0]) * zoom_factor\n",
    "\n",
    "    x_min = max(0, center_x - new_width / 2)\n",
    "    x_max = min(image_width, center_x + new_width / 2)\n",
    "\n",
    "    return [x_min, bbox[1], x_max, bbox[3]]\n",
    "\n",
    "def zoom_keypoints(keypoints, zoom_factor, image_width):\n",
    "    center_x = (keypoints[0] + keypoints[2]) / 2\n",
    "\n",
    "    new_x_0 = center_x - (center_x - keypoints[0]) * zoom_factor\n",
    "    new_x_2 = center_x + (keypoints[2] - center_x) * zoom_factor\n",
    "\n",
    "    return [new_x_0, keypoints[1], new_x_2, keypoints[3]]\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_data(image, bbox, keypoints):\n",
    "    augmented_data = []\n",
    "\n",
    "    # Original data\n",
    "    augmented_data.append((image, bbox, keypoints))\n",
    "\n",
    "    # Rotate 30°\n",
    "    rotated_image = cv2.warpAffine(image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), 30, 1), (image.shape[1], image.shape[0]))\n",
    "    rotated_bbox = rotate_bbox(bbox, 30, image.shape[1], image.shape[0])\n",
    "    rotated_keypoints = rotate_keypoints(keypoints, 30, image.shape[1], image.shape[0])\n",
    "    augmented_data.append((rotated_image, rotated_bbox, rotated_keypoints))\n",
    "\n",
    "    # Rotate -30°\n",
    "    rotated_image = cv2.warpAffine(image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), -30, 1), (image.shape[1], image.shape[0]))\n",
    "    rotated_bbox = rotate_bbox(bbox, -30, image.shape[1], image.shape[0])\n",
    "    rotated_keypoints = rotate_keypoints(keypoints, -30, image.shape[1], image.shape[0])\n",
    "    augmented_data.append((rotated_image, rotated_bbox, rotated_keypoints))\n",
    "\n",
    "    # Contrast +50\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=1.5, beta=0)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = keypoints\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # Contrast -50\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=0.5, beta=0)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = keypoints\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # Horizontal flip\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    flipped_bbox = flip_bbox(bbox, image.shape[1])\n",
    "    flipped_keypoints = flip_keypoints(keypoints, image.shape[1])\n",
    "    augmented_data.append((flipped_image, flipped_bbox, flipped_keypoints))\n",
    "\n",
    "    # Horizontal flip 30°\n",
    "    rotated_image = cv2.warpAffine(flipped_image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), 30, 1), (image.shape[1], image.shape[0]))\n",
    "    rotated_bbox = rotate_bbox(flipped_bbox, 30, image.shape[1], image.shape[0])\n",
    "    rotated_keypoints = rotate_keypoints(flipped_keypoints, 30, image.shape[1], image.shape[0])\n",
    "    augmented_data.append((rotated_image, rotated_bbox, rotated_keypoints))\n",
    "\n",
    "    # Horizontal flip -30°\n",
    "    rotated_image = cv2.warpAffine(flipped_image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), -30, 1), (image.shape[1], image.shape[0]))\n",
    "    rotated_bbox = rotate_bbox(flipped_bbox, -30, image.shape[1], image.shape[0])\n",
    "    rotated_keypoints = rotate_keypoints(flipped_keypoints, -30, image.shape[1], image.shape[0])\n",
    "    augmented_data.append((rotated_image, rotated_bbox, rotated_keypoints))\n",
    "\n",
    "    # Contrast Horizontal flip +50\n",
    "    contrast_image = cv2.convertScaleAbs(flipped_image, alpha=1.5, beta=0)\n",
    "    contrast_bbox = flip_bbox(flipped_bbox, image.shape[1])\n",
    "    contrast_keypoints = flip_keypoints(flipped_keypoints, image.shape[1])\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # Contrast Horizontal flip -50\n",
    "    contrast_image = cv2.convertScaleAbs(flipped_image, alpha=0.5, beta=0)\n",
    "    contrast_bbox = flip_bbox(flipped_bbox, image.shape[1])\n",
    "    contrast_keypoints = flip_keypoints(flipped_keypoints, image.shape[1])\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # Color change to red\n",
    "    red_image = image.copy()\n",
    "    red_image[:, :, 1] = 0  # Set green channel to 0\n",
    "    red_image[:, :, 2] = 0  # Set blue channel to 0\n",
    "    red_bbox = bbox\n",
    "    red_keypoints = keypoints\n",
    "    augmented_data.append((red_image, red_bbox, red_keypoints))\n",
    "\n",
    "    # Color change to green\n",
    "    green_image = image.copy()\n",
    "    green_image[:, :, 0] = 0  # Set blue channel to 0\n",
    "    green_image[:, :, 2] = 0  # Set red channel to 0\n",
    "    green_bbox = bbox\n",
    "    green_keypoints = keypoints\n",
    "    augmented_data.append((green_image, green_bbox, green_keypoints))\n",
    "\n",
    "    # Color change to purple\n",
    "    purple_image = image.copy()\n",
    "    purple_image[:, :, 0] = 128  # Set blue channel to half intensity\n",
    "    purple_image[:, :, 1] = 0    # Set green channel to 0\n",
    "    purple_bbox = bbox\n",
    "    purple_keypoints = keypoints\n",
    "    augmented_data.append((purple_image, purple_bbox, purple_keypoints))\n",
    "\n",
    "    # Horizontal zoom\n",
    "    zoom_factor = 0.8\n",
    "    zoom_image = cv2.resize(image, None, fx=zoom_factor, fy=1)\n",
    "    zoomed_bbox = zoom_bbox(bbox, zoom_factor, image.shape[1])\n",
    "    zoomed_keypoints = zoom_keypoints(keypoints, zoom_factor, image.shape[1])\n",
    "    augmented_data.append((zoom_image, zoomed_bbox, zoomed_keypoints))\n",
    "\n",
    "    # Horizontal zoom with flip\n",
    "    zoom_flip_image = cv2.flip(zoom_image, 1)\n",
    "    zoom_flip_bbox = flip_bbox(zoomed_bbox, zoom_image.shape[1])\n",
    "    zoom_flip_keypoints = flip_keypoints(zoomed_keypoints, zoom_image.shape[1])\n",
    "    augmented_data.append((zoom_flip_image, zoom_flip_bbox, zoom_flip_keypoints))\n",
    "\n",
    "    # Horizontal zoom with rotate 30°\n",
    "    rotated_zoom_image = cv2.warpAffine(zoom_image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), 30, 1), (image.shape[1], image.shape[0]))\n",
    "    rotated_zoom_bbox = rotate_bbox(zoomed_bbox, 30, image.shape[1], image.shape[0])\n",
    "    rotated_zoom_keypoints = rotate_keypoints(zoomed_keypoints, 30, image.shape[1], image.shape[0])\n",
    "    augmented_data.append((rotated_zoom_image, rotated_zoom_bbox, rotated_zoom_keypoints))\n",
    "\n",
    "    # Horizontal zoom with rotate -30°\n",
    "    rotated_zoom_image = cv2.warpAffine(zoom_image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), -30, 1), (image.shape[1], image.shape[0]))\n",
    "    rotated_zoom_bbox = rotate_bbox(zoomed_bbox, -30, image.shape[1], image.shape[0])\n",
    "    rotated_zoom_keypoints = rotate_keypoints(zoomed_keypoints, -30, image.shape[1], image.shape[0])\n",
    "    augmented_data.append((rotated_zoom_image, rotated_zoom_bbox, rotated_zoom_keypoints))\n",
    "    \n",
    "    # Convertir la imagen a escala de grises\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    magnitude = cv2.magnitude(sobel_x, sobel_y)\n",
    "    salient_edge_map = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "    salient_edge_bbox = bbox\n",
    "    salient_edge_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((salient_edge_map, salient_edge_bbox, salient_edge_keypoints))\n",
    "\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Perform data augmentation\n",
    "        augmented_data_list = augment_data(image, bbox, keypoints)\n",
    "\n",
    "        # Save augmented images and labels\n",
    "        for i, (augmented_image, augmented_bbox, augmented_keypoints) in enumerate(augmented_data_list):\n",
    "            augmented_image_path = os.path.join(output_dir, f'aug_{i}_{filename}')\n",
    "            cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            augmented_label_path = os.path.join(output_dir, f'aug_{i}_{filename[:-4]}.txt')\n",
    "            with open(augmented_label_path, 'w') as augmented_label_file:\n",
    "                augmented_label_file.write('0 {} {} {} {} '.format(*augmented_bbox))\n",
    "                augmented_label_file.write(' '.join(map(str, augmented_keypoints)))\n",
    "\n",
    "print(\"Data augmentation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8a5494",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'data_p\\\\img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 134\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m augmented_data\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Process each image and its corresponding annotation\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    136\u001b[0m         image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'data_p\\\\img'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define your input and output directories\n",
    "input_dir = 'data_p\\img'\n",
    "output_dir = 'dataug'\n",
    "label_dir = 'data_p\\lab'\n",
    "\n",
    "# Make sure the output directories exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_data(image, bbox, keypoints):\n",
    "    augmented_data = []\n",
    "\n",
    "    # Original data\n",
    "    #augmented_data.append((image, bbox, keypoints))\n",
    "\n",
    "    # 1- Contrast +50\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=1.5, beta=0)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # 2- Contrast -50\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=0.5, beta=0)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # 3- Contrast +75\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=1.50, beta=-200)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # 4- Contrast -75\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=0.75, beta=-190)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "    \n",
    "    # 5- Color Rojo\n",
    "    red_image = image.copy()\n",
    "    red_image[:, :, 1] = 0  # Set green channel to 0\n",
    "    red_image[:, :, 2] = 0  # Set blue channel to 0\n",
    "    red_bbox = bbox\n",
    "    red_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((red_image, red_bbox, red_keypoints))\n",
    "\n",
    "    # 6- Color Verde\n",
    "    green_image = image.copy()\n",
    "    green_image[:, :, 0] = 0  # Set blue channel to 0\n",
    "    green_image[:, :, 2] = 0  # Set red channel to 0\n",
    "    green_bbox = bbox\n",
    "    green_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((green_image, green_bbox, green_keypoints))\n",
    "\n",
    "    # 7- Color Purpura\n",
    "    purple_image = image.copy()\n",
    "    purple_image[:, :, 0] = 128  # Set blue channel to half intensity\n",
    "    purple_image[:, :, 1] = 0    # Set green channel to 0\n",
    "    purple_bbox = bbox\n",
    "    purple_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((purple_image, purple_bbox, purple_keypoints))\n",
    "\n",
    "    # 8- Color Amarillo\n",
    "    purple_image = image.copy()\n",
    "    purple_image[:, :, 2] = 50 # Set blue channel to half intensity\n",
    "    purple_image[:, 2, 1] = 128    # Set green channel to 0\n",
    "    purple_bbox = bbox\n",
    "    purple_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((purple_image, purple_bbox, purple_keypoints))\n",
    "\n",
    "    # 9- Color Azul\n",
    "    purple_image = image.copy()\n",
    "    purple_image[2, :, 0] = 128 # Set blue channel to half intensity\n",
    "    purple_image[:, :, 0] = 0    # Set green channel to 0\n",
    "    purple_bbox = bbox\n",
    "    purple_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((purple_image, purple_bbox, purple_keypoints))\n",
    "    \n",
    "    # 10- Contrast y Brillo +50\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=2.0, beta=-150)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "    \n",
    "    # 11- Des-Texturizado\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                       [1, -3, 1],\n",
    "                       [0, 1, 0]], dtype=np.float32)\n",
    "\n",
    "    edge_enhanced_image = cv2.filter2D(image, cv2.CV_8U, kernel)\n",
    "    edge_enhanced_bbox = bbox\n",
    "    edge_enhanced_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((edge_enhanced_image, edge_enhanced_bbox, edge_enhanced_keypoints))\n",
    "    \n",
    "    # 12- Convertir la imagen a escala de grises\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    magnitude = cv2.magnitude(sobel_x, sobel_y)\n",
    "    salient_edge_map = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "    salient_edge_bbox = bbox\n",
    "    salient_edge_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((salient_edge_map, salient_edge_bbox, salient_edge_keypoints))\n",
    "    \n",
    "    # 13- Contrast y Brillo +50\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=1.5, beta=50)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # 14- Contrast y Brillo -50\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=0.5, beta=-50)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # 15- Decolorar la imagen\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    decolor_bbox = bbox\n",
    "    decolor_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((gray_image, decolor_bbox, decolor_keypoints))\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Perform data augmentation\n",
    "        augmented_data_list = augment_data(image, bbox, keypoints)\n",
    "\n",
    "        # Save augmented images and labels\n",
    "        for i, (augmented_image, augmented_bbox, augmented_keypoints) in enumerate(augmented_data_list):\n",
    "            augmented_image_path = os.path.join(output_dir, f'aug_{i}_{filename}')\n",
    "            cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            augmented_label_path = os.path.join(output_dir, f'aug_{i}_{filename[:-4]}.txt')\n",
    "            with open(augmented_label_path, 'w') as augmented_label_file:\n",
    "                augmented_label_file.write('0 {} {} {} {} '.format(*augmented_bbox))\n",
    "                augmented_label_file.write(' '.join(map(str, augmented_keypoints)))\n",
    "\n",
    "print(\"Data augmentation complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c2622e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 118\u001b[0m\n\u001b[0;32m    115\u001b[0m label_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(label_dir, filename[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Read image\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Read label file\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define your input and output directories\n",
    "input_dir = 'golpes_3_340\\images'\n",
    "output_dir = 'dataug'\n",
    "label_dir = 'golpes_3_340\\labels'\n",
    "\n",
    "\n",
    "# Make sure the output directories exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Helper functions for bounding box and keypoints transformations\n",
    "def flip_bbox(bbox, image_width):\n",
    "    return [image_width - bbox[2], bbox[1], image_width - bbox[0], bbox[3]]\n",
    "\n",
    "def rotate_bbox(bbox, angle, image_width, image_height):\n",
    "    center_x = (bbox[0] + bbox[2]) / 2\n",
    "    center_y = (bbox[1] + bbox[3]) / 2\n",
    "\n",
    "    new_center_x = center_x * np.cos(np.radians(angle)) - center_y * np.sin(np.radians(angle))\n",
    "    new_center_y = center_x * np.sin(np.radians(angle)) + center_y * np.cos(np.radians(angle))\n",
    "\n",
    "    width = bbox[2] - bbox[0]\n",
    "    height = bbox[3] - bbox[1]\n",
    "\n",
    "    new_width = np.abs(width * np.cos(np.radians(angle))) + np.abs(height * np.sin(np.radians(angle)))\n",
    "    new_height = np.abs(height * np.cos(np.radians(angle))) + np.abs(width * np.sin(np.radians(angle)))\n",
    "\n",
    "    x_min = max(0, new_center_x - new_width / 2)\n",
    "    y_min = max(0, new_center_y - new_height / 2)\n",
    "    x_max = min(image_width, new_center_x + new_width / 2)\n",
    "    y_max = min(image_height, new_center_y + new_height / 2)\n",
    "\n",
    "    return [x_min, y_min, x_max, y_max]\n",
    "\n",
    "def rotate_keypoints(keypoints, angle, image_width, image_height):\n",
    "    rotated_keypoints = []\n",
    "    center_x = image_width / 2\n",
    "    center_y = image_height / 2\n",
    "\n",
    "    for i in range(0, len(keypoints), 2):\n",
    "        x = keypoints[i]\n",
    "        y = keypoints[i + 1]\n",
    "\n",
    "        # Translate to the origin\n",
    "        x -= center_x\n",
    "        y -= center_y\n",
    "\n",
    "        # Rotate\n",
    "        new_x = x * np.cos(np.radians(angle)) - y * np.sin(np.radians(angle))\n",
    "        new_y = x * np.sin(np.radians(angle)) + y * np.cos(np.radians(angle))\n",
    "\n",
    "        # Translate back to the original center\n",
    "        new_x += center_x\n",
    "        new_y += center_y\n",
    "\n",
    "        rotated_keypoints.extend([new_x, new_y])\n",
    "\n",
    "    return rotated_keypoints\n",
    "\n",
    "\n",
    "def flip_keypoints(keypoints, image_width):\n",
    "    flipped_keypoints = [image_width - kp if i % 2 == 0 else kp for i, kp in enumerate(keypoints)]\n",
    "    return flipped_keypoints\n",
    "\n",
    "def zoom_bbox(bbox, zoom_factor, image_width):\n",
    "    center_x = (bbox[0] + bbox[2]) / 2\n",
    "\n",
    "    new_width = (bbox[2] - bbox[0]) * zoom_factor\n",
    "\n",
    "    x_min = max(0, center_x - new_width / 2)\n",
    "    x_max = min(image_width, center_x + new_width / 2)\n",
    "\n",
    "    return [x_min, bbox[1], x_max, bbox[3]]  # Fix bbox[0] to bbox[1]\n",
    "\n",
    "\n",
    "def zoom_keypoints(keypoints, zoom_factor, image_width):\n",
    "    center_x = (keypoints[0] + keypoints[2]) / 2\n",
    "\n",
    "    new_x_0 = center_x - (center_x - keypoints[0]) * zoom_factor\n",
    "    new_x_2 = center_x + (keypoints[2] - center_x) * zoom_factor\n",
    "\n",
    "    return [new_x_0, keypoints[1], new_x_2, keypoints[3]]  # Fix keypoints[0] to keypoints[1]\n",
    "\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_data(image, bbox, keypoints):\n",
    "    augmented_data = []\n",
    "\n",
    "    # Original data\n",
    "    #augmented_data.append((image, bbox, keypoints))\n",
    "\n",
    "    # Rotate 30°\n",
    "    rotated_image = cv2.warpAffine(image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), 15, 1), (image.shape[1], image.shape[0]))\n",
    "    rotated_bbox = rotate_bbox(bbox, -15, image.shape[1], image.shape[0])\n",
    "    rotated_keypoints = rotate_keypoints(keypoints, -15, image.shape[1], image.shape[0])\n",
    "    augmented_data.append((rotated_image, rotated_bbox, rotated_keypoints))\n",
    "\n",
    "    # Rotate -30°\n",
    "    #rotated_image = cv2.warpAffine(image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), -30, 1), (image.shape[1], image.shape[0]))\n",
    "    #rotated_bbox = rotate_bbox(bbox, -30, image.shape[1], image.shape[0])\n",
    "    #rotated_keypoints = rotate_keypoints(keypoints, -30, image.shape[1], image.shape[0])\n",
    "    #augmented_data.append((rotated_image, rotated_bbox, rotated_keypoints))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Perform data augmentation\n",
    "        augmented_data_list = augment_data(image, bbox, keypoints)\n",
    "\n",
    "        # Save augmented images and labels\n",
    "        for i, (augmented_image, augmented_bbox, augmented_keypoints) in enumerate(augmented_data_list):\n",
    "            augmented_image_path = os.path.join(output_dir, f'aug_{i}_{filename}')\n",
    "            cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            augmented_label_path = os.path.join(output_dir, f'aug_{i}_{filename[:-4]}.txt')\n",
    "            with open(augmented_label_path, 'w') as augmented_label_file:\n",
    "                augmented_label_file.write('0 {} {} {} {} '.format(*augmented_bbox))\n",
    "                augmented_label_file.write(' '.join(map(str, augmented_keypoints)))\n",
    "\n",
    "print(\"Data augmentation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83b064ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 90\u001b[0m\n\u001b[0;32m     87\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, labels[\u001b[38;5;241m5\u001b[39m:]))\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Perform data augmentation\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m augmented_data_list \u001b[38;5;241m=\u001b[39m \u001b[43maugment_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Save augmented images and labels\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (augmented_image, augmented_bbox, augmented_keypoints) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(augmented_data_list):\n",
      "Cell \u001b[1;32mIn[46], line 64\u001b[0m, in \u001b[0;36maugment_data\u001b[1;34m(image, bbox, keypoints)\u001b[0m\n\u001b[0;32m     58\u001b[0m augmented_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Original data\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# augmented_data.append((image, bbox, keypoints))\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Rotate -15°\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m rotated_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarpAffine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetRotationMatrix2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m rotated_bbox \u001b[38;5;241m=\u001b[39m rotate_bbox(bbox, \u001b[38;5;241m15\u001b[39m, image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     66\u001b[0m rotated_keypoints \u001b[38;5;241m=\u001b[39m rotate_keypoints(keypoints, \u001b[38;5;241m15\u001b[39m, image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define your input and output directories\n",
    "input_dir = 'golpes_3_340\\images'\n",
    "output_dir = 'dataug'\n",
    "label_dir = 'golpes_3_340\\labels'\n",
    "\n",
    "# Make sure the output directories exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Helper functions for bounding box and keypoints transformations\n",
    "\n",
    "\n",
    "def rotate_bbox(bbox, angle, image_width, image_height):\n",
    "    center_x = (bbox[0] + bbox[2]) / 2\n",
    "    center_y = (bbox[1] + bbox[3]) / 2\n",
    "\n",
    "    # Calcular las nuevas coordenadas del centro después de la rotación\n",
    "    new_center_x = center_x * np.cos(np.radians(angle)) - center_y * np.sin(np.radians(angle))\n",
    "    new_center_y = center_x * np.sin(np.radians(angle)) + center_y * np.cos(np.radians(angle))\n",
    "\n",
    "    width = bbox[2] - bbox[0]\n",
    "    height = bbox[3] - bbox[1]\n",
    "\n",
    "    # Calcular las nuevas dimensiones de la bounding box después de la rotación\n",
    "    new_width = np.abs(width * np.cos(np.radians(angle))) + np.abs(height * np.sin(np.radians(angle)))\n",
    "    new_height = np.abs(height * np.cos(np.radians(angle))) + np.abs(width * np.sin(np.radians(angle)))\n",
    "\n",
    "    # Calcular las nuevas coordenadas de la bounding box después de la rotación\n",
    "    x_min = max(0, new_center_x - new_width / 2)\n",
    "    y_min = max(0, new_center_y - new_height / 2)\n",
    "    x_max = min(image_width, new_center_x + new_width / 2)\n",
    "    y_max = min(image_height, new_center_y + new_height / 2)\n",
    "\n",
    "    return [x_min, y_min, x_max, y_max]\n",
    "\n",
    "def rotate_keypoints(keypoints, angle, image_width, image_height):\n",
    "    rotated_keypoints = []\n",
    "\n",
    "    # Iterar sobre las coordenadas x, y de los keypoints\n",
    "    for i in range(0, len(keypoints), 2):\n",
    "        x = keypoints[i]\n",
    "        y = keypoints[i + 1]\n",
    "\n",
    "        # Calcular las nuevas coordenadas después de la rotación\n",
    "        new_x = x * np.cos(np.radians(angle)) - y * np.sin(np.radians(angle))\n",
    "        new_y = x * np.sin(np.radians(angle)) + y * np.cos(np.radians(angle))\n",
    "\n",
    "        rotated_keypoints.extend([new_x, new_y])\n",
    "\n",
    "    return rotated_keypoints\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_data(image, bbox, keypoints):\n",
    "    augmented_data = []\n",
    "\n",
    "    # Original data\n",
    "    # augmented_data.append((image, bbox, keypoints))\n",
    "\n",
    "    # Rotate -15°\n",
    "    rotated_image = cv2.warpAffine(image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), -15, 1), (image.shape[1], image.shape[0]))\n",
    "    rotated_bbox = rotate_bbox(bbox, 15, image.shape[1], image.shape[0])\n",
    "    rotated_keypoints = rotate_keypoints(keypoints, 15, image.shape[1], image.shape[0])\n",
    "    augmented_data.append((rotated_image, rotated_bbox, rotated_keypoints))\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Perform data augmentation\n",
    "        augmented_data_list = augment_data(image, bbox, keypoints)\n",
    "\n",
    "        # Save augmented images and labels\n",
    "        for i, (augmented_image, augmented_bbox, augmented_keypoints) in enumerate(augmented_data_list):\n",
    "            augmented_image_path = os.path.join(output_dir, f'aug_{i}_{filename}')\n",
    "            cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            augmented_label_path = os.path.join(output_dir, f'aug_{i}_{filename[:-4]}.txt')\n",
    "            with open(augmented_label_path, 'w') as augmented_label_file:\n",
    "                augmented_label_file.write('0 {} {} {} {} '.format(*augmented_bbox))\n",
    "                augmented_label_file.write(' '.join(map(str, augmented_keypoints)))\n",
    "\n",
    "print(\"Data augmentation complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b1d8abf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[0;32m     42\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnnotations Verification\u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mcvtColor(image_with_annotations, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR))\n\u001b[1;32m---> 43\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def draw_bbox_and_keypoints(image,  keypoints, color=(255, 0, 0)):\n",
    "\n",
    "    # Draw keypoints\n",
    "    for i in range(0, len(keypoints), 2):\n",
    "        kp_x = int(keypoints[i] * image.shape[1])\n",
    "        kp_y = int(keypoints[i + 1] * image.shape[0])\n",
    "        cv2.circle(image, (kp_x, kp_y), 3, color, -1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define your input directory\n",
    "input_dir = 'data\\images\\train'\n",
    "\n",
    "label_dir = 'dataug'\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Draw bounding box and keypoints on the image\n",
    "        image_with_annotations = draw_bbox_and_keypoints(image.copy(), keypoints)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Annotations Verification', cv2.cvtColor(image_with_annotations, cv2.COLOR_RGB2BGR))\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc79a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define your input and output directories\n",
    "input_dir = 'nose\\img'\n",
    "output_dir = 'dataug'\n",
    "label_dir = 'nose\\lab'\n",
    "\n",
    "# Make sure the output directories exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_data(image, bbox, keypoints):\n",
    "    augmented_data = []\n",
    "\n",
    "    # Original data\n",
    "    #augmented_data.append((image, bbox, keypoints))\n",
    "\n",
    "    # Horizontal flip\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    flipped_bbox = [1 - bbox[2], bbox[1], 1 - bbox[0], bbox[3]]  # Adjust bounding box x-coordinates\n",
    "    flipped_keypoints = [1 - kp if i % 2 == 0 else kp for i, kp in enumerate(keypoints)]\n",
    "    augmented_data.append((flipped_image, flipped_bbox, flipped_keypoints))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Perform data augmentation\n",
    "        augmented_data_list = augment_data(image, bbox, keypoints)\n",
    "\n",
    "        # Save augmented images and labels\n",
    "        for i, (augmented_image, augmented_bbox, augmented_keypoints) in enumerate(augmented_data_list):\n",
    "            augmented_image_path = os.path.join(output_dir, f'aug_{i}_{filename}')\n",
    "            cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            augmented_label_path = os.path.join(output_dir, f'aug_{i}_{filename[:-4]}.txt')\n",
    "            with open(augmented_label_path, 'w') as augmented_label_file:\n",
    "                augmented_label_file.write('0 {} {} {} {} '.format(*augmented_bbox))\n",
    "                augmented_label_file.write(' '.join(map(str, augmented_keypoints)))\n",
    "\n",
    "print(\"Data augmentation complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da6e65d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (augmented_image, augmented_bbox, augmented_keypoints) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(augmented_data_list):\n\u001b[0;32m     57\u001b[0m     augmented_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maug_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_RGB2BGR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     augmented_label_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maug_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(augmented_label_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m augmented_label_file:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define your input and output directories\n",
    "input_dir = 'golpes_3_340\\images'\n",
    "output_dir = 'dataug'\n",
    "label_dir = 'golpes_3_340\\labels'\n",
    "\n",
    "# Make sure the output directories exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_data(image, bbox, keypoints):\n",
    "    augmented_data = []\n",
    "\n",
    "    # Original data\n",
    "    #augmented_data.append((image, bbox, keypoints))\n",
    "    # Contrast +50\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=1.5, beta=0)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = keypoints\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    # Contrast -50\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=0.5, beta=0)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = keypoints\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Perform data augmentation\n",
    "        augmented_data_list = augment_data(image, bbox, keypoints)\n",
    "\n",
    "        # Save augmented images and labels\n",
    "        for i, (augmented_image, augmented_bbox, augmented_keypoints) in enumerate(augmented_data_list):\n",
    "            augmented_image_path = os.path.join(output_dir, f'aug_{i}_{filename}')\n",
    "            cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            augmented_label_path = os.path.join(output_dir, f'aug_{i}_{filename[:-4]}.txt')\n",
    "            with open(augmented_label_path, 'w') as augmented_label_file:\n",
    "                augmented_label_file.write('0 {} {} {} {} '.format(*augmented_bbox))\n",
    "                augmented_label_file.write(' '.join(map(str, augmented_keypoints)))\n",
    "\n",
    "print(\"Data augmentation complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c18c410",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (augmented_image, augmented_bbox, augmented_keypoints) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(augmented_data_list):\n\u001b[0;32m     52\u001b[0m     augmented_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maug_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_RGB2BGR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     augmented_label_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maug_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(augmented_label_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m augmented_label_file:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define your input and output directories\n",
    "input_dir = 'golpes_3_340\\images'\n",
    "output_dir = 'dataug'\n",
    "label_dir = 'golpes_3_340\\labels'\n",
    "\n",
    "# Make sure the output directories exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_data(image, bbox, keypoints):\n",
    "    augmented_data = []\n",
    "\n",
    "    # Original data\n",
    "    #augmented_data.append((image, bbox, keypoints))\n",
    "\n",
    "    # 3- Contrast +75\n",
    "    contrast_image = cv2.convertScaleAbs(image, alpha=2.0, beta=-150)\n",
    "    contrast_bbox = bbox\n",
    "    contrast_keypoints = [kp for kp in keypoints]\n",
    "    augmented_data.append((contrast_image, contrast_bbox, contrast_keypoints))\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Process each image and its corresponding annotation\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename[:-4] + '.txt')\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = label_file.readline().split()\n",
    "\n",
    "        # Extract bounding box and keypoints from labels\n",
    "        bbox = list(map(float, labels[1:5]))\n",
    "        keypoints = list(map(float, labels[5:]))\n",
    "\n",
    "        # Perform data augmentation\n",
    "        augmented_data_list = augment_data(image, bbox, keypoints)\n",
    "\n",
    "        # Save augmented images and labels\n",
    "        for i, (augmented_image, augmented_bbox, augmented_keypoints) in enumerate(augmented_data_list):\n",
    "            augmented_image_path = os.path.join(output_dir, f'aug_{i}_{filename}')\n",
    "            cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            augmented_label_path = os.path.join(output_dir, f'aug_{i}_{filename[:-4]}.txt')\n",
    "            with open(augmented_label_path, 'w') as augmented_label_file:\n",
    "                augmented_label_file.write('0 {} {} {} {} '.format(*augmented_bbox))\n",
    "                augmented_label_file.write(' '.join(map(str, augmented_keypoints)))\n",
    "\n",
    "print(\"Data augmentation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291e29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2428780a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
